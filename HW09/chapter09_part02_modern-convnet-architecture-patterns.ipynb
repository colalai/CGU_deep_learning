{"cells":[{"cell_type":"markdown","metadata":{"id":"nDUek4K7MqyJ"},"source":["This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n","\n","**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n","\n","This notebook was generated for TensorFlow 2.6."]},{"cell_type":"markdown","metadata":{"id":"77kpHa7FMqyP"},"source":["## Modern convnet architecture patterns"]},{"cell_type":"markdown","metadata":{"id":"Fw-ZBcP0MqyQ"},"source":["### Modularity, hierarchy, and reuse"]},{"cell_type":"markdown","metadata":{"id":"WLZ727IiMqyQ"},"source":["### Residual connections"]},{"cell_type":"markdown","metadata":{"id":"8gIosTlMMqyR"},"source":["**Residual block where the number of filters changes**"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4616,"status":"ok","timestamp":1669722222091,"user":{"displayName":"Cola Lai","userId":"04494729756123350755"},"user_tz":-480},"id":"kCFHhibNMqyS"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","inputs = keras.Input(shape=(32, 32, 3))\n","x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n","residual = x\n","x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n","residual = layers.Conv2D(64, 1)(residual)\n","x = layers.add([x, residual])"]},{"cell_type":"markdown","metadata":{"id":"QW7ghZtrMqyT"},"source":["**Case where target block includes a max pooling layer**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1669722222092,"user":{"displayName":"Cola Lai","userId":"04494729756123350755"},"user_tz":-480},"id":"sQAskDOvMqyU"},"outputs":[],"source":["inputs = keras.Input(shape=(32, 32, 3))\n","x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n","residual = x\n","x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.MaxPooling2D(2, padding=\"same\")(x)\n","residual = layers.Conv2D(64, 1, strides=2)(residual)\n","x = layers.add([x, residual])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543,"status":"ok","timestamp":1669722222631,"user":{"displayName":"Cola Lai","userId":"04494729756123350755"},"user_tz":-480},"id":"sKoHicFAMqyU","outputId":"984048eb-dad7-4316-d003-f53aeff7ee0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","rescaling (Rescaling)           (None, 32, 32, 3)    0           input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 32)   896         rescaling[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 16, 16, 32)   128         rescaling[0][0]                  \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 16, 16, 32)   0           max_pooling2d_1[0][0]            \n","                                                                 conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 16, 16, 64)   18496       add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 8, 8, 64)     2112        add_3[0][0]                      \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_2[0][0]            \n","                                                                 conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 8, 8, 128)    73856       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 8, 8, 128)    8320        add_4[0][0]                      \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 8, 8, 128)    0           conv2d_16[0][0]                  \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 128)          0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            129         global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 297,697\n","Trainable params: 297,697\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["inputs = keras.Input(shape=(32, 32, 3))\n","x = layers.Rescaling(1./255)(inputs)\n","\n","def residual_block(x, filters, pooling=False):\n","    residual = x\n","    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n","    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n","    if pooling:\n","        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n","        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n","    elif filters != residual.shape[-1]:\n","        residual = layers.Conv2D(filters, 1)(residual)\n","    x = layers.add([x, residual])\n","    return x\n","\n","x = residual_block(x, filters=32, pooling=True)\n","x = residual_block(x, filters=64, pooling=True)\n","x = residual_block(x, filters=128, pooling=False)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"EZZJTb7SMqyV"},"source":["### Batch normalization"]},{"cell_type":"markdown","metadata":{"id":"q9_lEDP0MqyV"},"source":["### Depthwise separable convolutions"]},{"cell_type":"markdown","metadata":{"id":"U9hFruCfMqyV"},"source":["### Putting it together: A mini Xception-like model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":41},"id":"hd7ZveifMqyV"},"outputs":[],"source":["'''from google.colab import files\n","files.upload()'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e1lrSnXSMqyW"},"outputs":[],"source":["'''!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle competitions download -c dogs-vs-cats\n","!unzip -qq train.zip'''"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"id":"YgKQ_6_2MqyW"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 files belonging to 2 classes.\n","Found 1000 files belonging to 2 classes.\n","Found 2000 files belonging to 2 classes.\n"]}],"source":["import os, shutil, pathlib\n","from tensorflow.keras.utils import image_dataset_from_directory\n","\n","original_dir = pathlib.Path(\"C:\\\\Users\\\\Cola\\\\Desktop\\\\dogs-vs-cats\\\\train\\\\train\")\n","new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n","\n","def make_subset(subset_name, start_index, end_index):\n","    for category in (\"cat\", \"dog\"):\n","        dir = new_base_dir / subset_name / category\n","        os.makedirs(dir)\n","        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n","        for fname in fnames:\n","            shutil.copyfile(src=original_dir / fname,\n","                            dst=dir / fname)\n","\n","make_subset(\"train\", start_index=0, end_index=1000)\n","make_subset(\"validation\", start_index=1000, end_index=1500)\n","make_subset(\"test\", start_index=1500, end_index=2500)\n","\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4WlFWfBmMqyW"},"outputs":[],"source":["from keras import layers\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.2),\n","    ]\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"v6H1iMK0MqyX"},"outputs":[],"source":["inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","\n","x = layers.Rescaling(1./255)(x)\n","x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n","\n","for size in [32, 64, 128, 256, 512]:\n","    residual = x\n","\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n","\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n","\n","    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","\n","    residual = layers.Conv2D(\n","        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n","    x = layers.add([x, residual])\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"XifZkafeMqyX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","63/63 [==============================] - 181s 3s/step - loss: 0.7218 - accuracy: 0.5630 - val_loss: 0.7060 - val_accuracy: 0.5000\n","Epoch 2/5\n","63/63 [==============================] - 180s 3s/step - loss: 0.6585 - accuracy: 0.6005 - val_loss: 0.7016 - val_accuracy: 0.5000\n","Epoch 3/5\n","63/63 [==============================] - 143s 2s/step - loss: 0.6428 - accuracy: 0.6265 - val_loss: 0.6990 - val_accuracy: 0.5000\n","Epoch 4/5\n","63/63 [==============================] - 168s 3s/step - loss: 0.6358 - accuracy: 0.6300 - val_loss: 0.7165 - val_accuracy: 0.5000\n","Epoch 5/5\n","63/63 [==============================] - 170s 3s/step - loss: 0.6156 - accuracy: 0.6610 - val_loss: 0.7441 - val_accuracy: 0.5000\n"]}],"source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])\n","history = model.fit(\n","    train_dataset,\n","    epochs=5,\n","    validation_data=validation_dataset)"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter09_part02_modern-convnet-architecture-patterns.ipynb","timestamp":1669722192307}],"version":""},"kernelspec":{"display_name":"Python 3.8.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"vscode":{"interpreter":{"hash":"63e27ca1d34725cacce143b37ee63271e2dce1666b3fb3b63887d92a860c4d6b"}}},"nbformat":4,"nbformat_minor":0}
